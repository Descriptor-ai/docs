---
title: 'Getting Started'
description: 'Learn how to use Descriptor.AI API'
---

## Getting started
<AccordionGroup>
<Accordion title="API">
<Note>
  **Prerequisite**: Please verify amount of channels in the audio file before proceeding.
</Note>
### Once obtained your API key, you can start using the API by following the [Quickstart Guide](/quickstart).

To get the most out of our API, please refer to the [Understanding Insights & Metrics](#understanding-insights--metrics) section.

### Parameters and Configuration

`language_code`: Language for ASR (e.g., en-US).

`transcript_model`: Model for transcription (default is `descriptor`).

`emotions_model`: Model for emotion analysis; set to null if not required.

`emotions_alignment`: Alignment for emotion analysis; set to null if not required. Aligns speakers phrases with emotions with a higher granularity.

`emotions_diarization`: Diarization for emotion analysis; set to null if not required. Answers the question who spoke what and how. Useful with alignment.

`channels`: Number of audio channels to process. Maximum is 8.

`insights`: Define insights to extract (summary, topics, labeling, etc.). For each of insights the provider can be set separately.

`sentiment_llm_provider`: specify the LLM provider for sentiment analysis (default is `azure`).

`metrics`: Choose from speech and emo (omit emo if emotion analysis is not needed).

`webhook`: URL to receive completed data.


### Step 4. Response Overview

Once processed, the response will contain the following information:

- **CallTranscript**: Text transcription with timestamps for each speaker.
- **Emotion Analysis** (if enabled): Emotion markers per phrase, including sentiment and intensity.
- **Insights**: Extracted insights such as summary, topics, customer issues, labeling, CSAT score, agent actions, and customer requests/questions.
- **Metrics**: Calculated metrics including speech and emotional metrics as configured.
For more details, please visit [api-reference](api-reference/endpoint/get)
This JSON response can be integrated into your system or visualized in a GUI for further analysis at https://demo.descriptor.ai/result/{result_id}. 

If a webhook URL was provided in the configuration, the system will automatically send the completed results to the specified endpoint.
</Accordion>
<Accordion title="Demo App">

For your convenience, we've prepared a demo app that showcases the capabilities of Descriptor.AI. 
It's not required to run the app to use the API, but it might help you to understand how to use the API and what results you can get.
<Info>
We don't provide the app for production use, so please don't use it in a production environment.
</Info>

Demo is available at [demo.descriptor.ai](https://demo.descriptor.ai).
</Accordion>
</AccordionGroup>

