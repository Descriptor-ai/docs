---
title: 'Features'
description: 'Learn about the capabilities of Descriptor.AI'
---

## What we offer

Transform customer interactions with enterprise-grade analytics:

<CardGroup>

<Card title="Advanced Speech Intelligence" icon="waveform-lines">
  ✅ Crystal-clear multi-speaker transcriptions with precise timestamps
  
  ✅ Emotion detection based on voice patterns and speech characteristics
  
  ✅ Real-time sentiment analysis for customer experience monitoring
  
  ❌ We don't claim to detect lies or deception
  
</Card>

<Card title="Strategic Conversation Analysis" icon="chart-network">
  ✅ Executive summaries of key conversation points
  
  ✅ Topic clustering to identify common themes
  
  ✅ Issue detection and resolution tracking
    
  ❌ We don't provide legal advice
</Card>

<Card title="Business Intelligence" icon="magnifying-glass-chart">
  ✅ Custom conversation categorization
  
  ✅ Data-driven CSAT scoring
  
  ✅ Agent performance analytics
  
  ❌ We don't make business decisions for you
  
</Card>

<Card title="Performance Analytics" icon="chart-mixed">
  ✅ Conversation dynamics analysis
  
  ✅ Emotional intelligence metrics
  
  ✅ Actionable improvement insights
    
  ❌ We don't make hiring/firing recommendations
</Card>

</CardGroup>

Our enterprise-ready solution transforms conversations into actionable business intelligence while maintaining ethical boundaries and realistic expectations.

<Info>
Due to the high volume of requests, currently we only support batch processing. 
Bulk processing will be available soon.
</Info>
## Getting started
<AccordionGroup>
<Accordion title="API">
<Note>
  **Prerequisite**: Please verify amount of channels in the audio file before proceeding.
</Note>
### Once obtained your API key, you can start using the API by following the [Quickstart Guide](/quickstart).

To get the most out of our API, please refer to the [Understanding Insights & Metrics](#understanding-insights--metrics) section.

### Parameters and Configuration

`language_code`: Language for ASR (e.g., en-US).

`transcript_model`: Model for transcription (default is `descriptor`).

`emotions_model`: Model for emotion analysis; set to null if not required.

`emotions_alignment`: Alignment for emotion analysis; set to null if not required. Aligns speakers phrases with emotions with a higher granularity.

`emotions_diarization`: Diarization for emotion analysis; set to null if not required. Answers the question who spoke what and how. Useful with alignment.

`channels`: Number of audio channels to process. Maximum is 8.

`insights`: Define insights to extract (summary, topics, labeling, etc.). For each of insights the provider can be set separately.

`sentiment_llm_provider`: specify the LLM provider for sentiment analysis (default is `azure`).

`metrics`: Choose from speech and emo (omit emo if emotion analysis is not needed).

`webhook`: URL to receive completed data.


### Step 4. Response Overview

Once processed, the response will contain the following information:

- **CallTranscript**: Text transcription with timestamps for each speaker.
- **Emotion Analysis** (if enabled): Emotion markers per phrase, including sentiment and intensity.
- **Insights**: Extracted insights such as summary, topics, customer issues, labeling, CSAT score, agent actions, and customer requests/questions.
- **Metrics**: Calculated metrics including speech and emotional metrics as configured.
For more details, please visit [api-reference](api-reference/endpoint/get)
This JSON response can be integrated into your system or visualized in a GUI for further analysis at https://demo.descriptor.ai/result/{result_id}. 

If a webhook URL was provided in the configuration, the system will automatically send the completed results to the specified endpoint.
</Accordion>
<Accordion title="Demo App">

For your convenience, we've prepared a demo app that showcases the capabilities of Descriptor.AI. 
It's not required to run the app to use the API, but it might help you to understand how to use the API and what results you can get.
<Info>
We don't provide the app for production use, so please don't use it in a production environment.
</Info>

Demo is available at [demo.descriptor.ai](https://demo.descriptor.ai).
</Accordion>
</AccordionGroup>

## Understanding Insights & Metrics

### Insights
<AccordionGroup>
<Accordion title="Summary">
**Purpose**: Provides a concise description of the conversation's main points.

**Output**: A brief text summary capturing the essence of the dialogue between the agent and customer.

</Accordion>
<Accordion title="Topics">
**Purpose**: Identifies and lists the main topics discussed.

**Output**: Array of keywords or phrases representing each topic covered in the conversation.

</Accordion>
<Accordion title="Problems">
**Purpose**: Highlights customer-reported issues and whether they were resolved.

**Output**: List of identified problems with resolution status and timestamps (links to specific dialogue portions).

</Accordion>
<Accordion title="Labeling">
**Purpose**: Tags the conversation's primary category based on user-defined labels, aiding in classification.

**Output**: A label that characterizes the dialogue type, such as "support inquiry" or "technical issue".

**Customization**: Supports a user-defined list of categories to choose the appropriate label.
</Accordion>
<Accordion title="CSAT">
**Purpose**: Assesses customer satisfaction through problem resolution and emotional analysis.

**Output**: Satisfaction score ranging from 0 to 10, factoring in problem resolution and emotional context.

</Accordion>
<Accordion title="AgentActions">
**Purpose**: Documents key actions taken by the agent during the conversation.

**Output**: Array of actions (e.g., provided solutions, asked for clarification) with timestamps.

</Accordion>
<Accordion title="Questions">

**Purpose**: Lists questions posed by the customer during the conversation.

**Output**: Array of questions asked by the customer, with timestamps for reference.

</Accordion>
<Accordion title="CustomerRequests">

**Purpose**: Captures specific requests or inquiries made by the customer to the agent.

**Output**: List of requests or inquiries, with timestamps indicating where in the conversation they occurred.

</Accordion>
</AccordionGroup>

### Metrics

#### Speech Metrics

<AccordionGroup>

<Accordion title="Total Call Duration">

**Definition**: The overall length of the conversation.

**Calculation**: Summing the duration from start to end of the audio file.

**Unit**: Seconds.
</Accordion>
<Accordion title="Speaker to Silence Ratio">

**Definition**: The ratio of each speaker’s talking time to silence time.

**Calculation**: Duration of speech divided by silence duration per speaker.

</Accordion>
<Accordion title="Total Speech to Silence Ratio">

**Definition**: Ratio of overall speaking time to silence during the entire conversation.

**Calculation**: Total time spoken by all participants divided by total silence time.

</Accordion>
<Accordion title="Speaker Speech Ratio">

**Definition**: The proportion of total speaking time for each speaker.

**Calculation**: Individual speaker’s talk duration divided by total conversation time.

</Accordion>
<Accordion title="Simultaneous Speech Time">

**Definition**: Time when two or more participants are speaking simultaneously.

**Calculation**: Summing overlapping talk times for each speaker pair.

</Accordion>
<Accordion title="Simultaneous Speech Ratio">

**Definition**: Ratio of simultaneous speaking time to total conversation time.

**Calculation**: Simultaneous speech time divided by total call duration.

</Accordion>
<Accordion title="Interruption Count">

**Definition**: Number of times one speaker interrupts another.

**Calculation**: Counting instances where a new speaker starts before the current one finishes.

</Accordion>
<Accordion title="Interruption Rate">

**Definition**: Frequency of interruptions per unit time.

**Calculation**: Interruption count divided by total speaking time of all participants.
</Accordion>
</AccordionGroup>

#### Emotion Metrics

<AccordionGroup>

<Accordion title="CSAT Rate">

**Definition**: Evaluates customer satisfaction based on emotional tone and problem-solving effectiveness.

**Calculation**: Derived from the percentage of issues resolved and weighted emotional states, scaled between 0 and 10.

</Accordion>
<Accordion title="DSAT (Dissatisfaction Score)">

**Definition**: Measures levels of customer dissatisfaction, focusing on unresolved issues or negative emotions.

**Calculation**: Based on unresolved problems and intensity of negative emotions during the conversation.
</Accordion>
<Accordion title="Emotional Volatility">

**Definition**: Tracks frequency of emotional changes within the conversation.

**Calculation**: Counts changes in emotional states and normalizes by total emotional shifts.
</Accordion>
<Accordion title="Emotional Evolution">

**Definition**: Indicates the progression of emotions from start to end.

**Calculation**: Normalized scoring of emotional states over time for each participant.
</Accordion>
<Accordion title="Emotional Phrases">

**Definition**: Highlights specific phrases where participants expressed non-neutral emotions.

**Calculation**: Extracts phrases tagged with emotional markers and lists them with timestamps.
</Accordion>
</AccordionGroup>
