---
title: 'Quickstart'
description: 'Quickstart guide to using our API with the command line'
---
You can start using our API with the command line following these steps:

1. Send a POST request with **audio file link** and **corresponding configuration** in JSON.
2. Send a GET request to fetch results using the **result_id** from the response.
3. _Optional_: Configure a **webhook** to receive the results.

**POST request sample**


<CodeGroup>

```
curl -X 'POST' \
  'https://demo.descriptor.ai/api/v1/offline/processing' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer YOUR_TOKEN_HERE' \
  -H 'Content-Type: application/json' \
  -d '{
  "config": {
    "language_code": "he-IL",
    "transcript_model": "descriptor-hebrew",
    "emotions_model": "emotions",
    "emotions_alignment": false,
    "emotions_diarization": false,
    "emotions_sentiment": false,
    "sentiment_llm_provider": "azure",
    "channels": 1,
    "insights": {
      "summary": {
        "provider": "azure"
      }
    },
    "metrics": [],
    "webhook": "https://example.com/"
  },
  "audio": {
    "uri": "https://example.com/"
  }
}
```
</CodeGroup>

**GET results**


Once the audio analysis is complete, you can retrieve the results using the unique **result_id** provided in the initial response. 
To access the analysis result in JSON format, make a GET request to the [following endpoint](api-reference/endpoint/get).

```
curl -X 'GET' \
  'https://demo.descriptor.ai/api/v1/offline/processing/{result_id}' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer YOUR_ACCESS_TOKEN'
```

<Note>
Replace `{result_id}` with the actual ID received in the response when you submitted the audio file for processing.
</Note>